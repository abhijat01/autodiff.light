{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import torch.optim as optim \n",
    "import sys \n",
    "import os \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dense =  nn.Linear(3,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3277, -0.5113,  0.2430],\n",
      "        [-0.5220,  0.5236, -0.0761]])\n",
      "tensor([0.5410, 0.1020])\n",
      "------ w >>\n",
      "array([[ 1,  3, -1],\n",
      "       [ 0, -4,  2]])\n",
      "------ x >>\n",
      "array([[ 1,  2, -1],\n",
      "       [-1,  3, -2]])\n",
      "----- b >>\n",
      "array([-3,  2])\n",
      "---- final value ----\n",
      "array([[  5,  -8],\n",
      "       [  7, -14]])\n",
      "tensor([-3.,  2.])\n"
     ]
    }
   ],
   "source": [
    "net = Net() \n",
    "print(\"Printing dense layer weights...\")\n",
    "print(net.dense.weight.data)\n",
    "print(net.dense.bias.data)\n",
    "print(\"finished printing dense layer weights\")\n",
    "model_w = np.array([[1, 3, -1], [0, -4, 2]])\n",
    "model_b = np.array([-3, 2])\n",
    "w_tensor = torch.from_numpy(model_w).float()\n",
    "b_tensor = torch.from_numpy(model_b).float() \n",
    "w = nn.Parameter(w_tensor)\n",
    "b = nn.Parameter(b_tensor)\n",
    "net.dense.weight  = w \n",
    "net.dense.bias = b\n",
    "x = np.array([[1, -1], [2, 3], [-1, -2]]).T\n",
    "print(\"------ w >>\")\n",
    "print(repr(model_w))\n",
    "print(\"------ x >>\")\n",
    "print(repr(x))\n",
    "print(\"----- b >>\")\n",
    "print(repr(model_b))\n",
    "yy = x@model_w.T + model_b \n",
    "print(\"---- final value ----\")\n",
    "print(repr(yy))\n",
    "print(net.dense.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "Output:tensor([[  5.,  -8.],\n",
      "        [  7., -14.]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.from_numpy(x).float() \n",
    "print(input.shape)\n",
    "output = net(input)\n",
    "print(\"Output:{}\".format(output.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output --- \n",
      "tensor([[  5.,  -8.],\n",
      "        [  7., -14.]])\n",
      "\n",
      "Kernel ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'conv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-218afa594b5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nKernel ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nBias ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 576\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Net' object has no attribute 'conv'"
     ]
    }
   ],
   "source": [
    "print(\"Output --- \")\n",
    "print(output.data)\n",
    "print(\"\\nKernel ---\")\n",
    "print(net.conv.weight.data)\n",
    "print(\"\\nBias ---\")\n",
    "print(net.conv.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_back = np.ones_like(output.data)\n",
    "target = torch.from_numpy(grad_back) \n",
    "criteria = nn.MSELoss()\n",
    "loss = criteria(output, target)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "    \n",
    "# perform a backward pass (backpropagation)\n",
    "loss.backward()\n",
    "    \n",
    "# Update the parameters\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9847, -1.0229],\n",
      "          [-0.0207,  1.9636]]]])\n",
      "tensor([[[[15.3333, 22.8889],\n",
      "          [20.6667, 36.4444]]]])\n",
      "Now printing the bias after gradient descent step\n",
      "Parameter containing:\n",
      "tensor([-0.0064], requires_grad=True)\n",
      "tensor([6.4444])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv.weight.data)\n",
    "print(net.conv.weight.grad)\n",
    "print(\"Now printing the bias after gradient descent step\")\n",
    "print(net.conv.bias)\n",
    "print(net.conv.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 1. 1.]\n",
      "   [1. 1. 1.]\n",
      "   [1. 1. 1.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(grad_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias gradient:tensor([6.4444])\n",
      "Bias after update:tensor([-0.0064])\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias gradient:{}\".format(net.conv.bias.grad))\n",
    "print(\"Bias after update:{}\".format(net.conv.bias.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=np.array([[ 1,  3, -1],\n",
    "       [ 0, -4,  2]])\n",
    "B=np.array([[-3],\n",
    "       [ 2]])\n",
    "X=np.array([[ 1, -1],\n",
    "       [ 2,  3],\n",
    "       [-1, -2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5,   7],\n",
       "       [ -8, -14]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W@X+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5,  -8],\n",
       "       [  7, -14]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T@W.T + B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5., -13.],\n",
       "        [ 12., -14.]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(input, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
